{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "import pennylane as qml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./pptnqfe.mplstyle')\n",
    "\n",
    "from qulearn.hat_basis import HatBasis\n",
    "from qulearn.trainer import SupervisedTrainer\n",
    "from qulearn.qlayer import (HatBasisQFE,\n",
    "                            TwoQubitRotCXMPSLayer,\n",
    "                            embedU,\n",
    "                            ParallelIQPEncoding,\n",
    "                            AltRotCXLayer,\n",
    "                            MeasurementLayer,\n",
    "                            HamiltonianLayer,\n",
    "                            MeasurementType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 2\n",
    "num_nodes = 2**num_qubits\n",
    "a = -1.0\n",
    "b = 1.0\n",
    "hat_basis = HatBasis(a=a, b=b, num_nodes=num_nodes)\n",
    "\n",
    "num_pnts = 500\n",
    "xvals = torch.linspace(-1.0, 1.0, num_pnts)\n",
    "basis_vectors = hat_basis.eval_basis_vector(xvals)\n",
    "basis_vectors = torch.sqrt(basis_vectors)\n",
    "\n",
    "num_subplots = num_nodes * (num_nodes + 1) // 2\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15, 10))\n",
    "axs_flat = axs.flatten()\n",
    "\n",
    "subplot_idx = 0\n",
    "for i in range(num_nodes):\n",
    "    for j in range(i + 1):\n",
    "        axs_flat[subplot_idx].plot(xvals, basis_vectors[:, i] * basis_vectors[:, j])\n",
    "        axs_flat[subplot_idx].set_title(f'$\\\\varphi_{i}\\\\varphi_{j}$')\n",
    "        axs_flat[subplot_idx].set_xlabel('$x$')\n",
    "        subplot_idx += 1\n",
    "\n",
    "for idx in range(subplot_idx, len(axs_flat)):\n",
    "    fig.delaxes(axs_flat[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/basis_funcs.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M2)â”€â”¤  <Z>\n",
      "1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M1)â”€â•°U(M2)â”€â”¤     \n",
      "2: â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M1)â”€â•°U(M1)â”€â”€â”€â”€â”€â”€â”€â”€â”¤     \n",
      "3: â”€â•­U(M0)â”€â•°U(M1)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     \n",
      "4: â”€â•°U(M0)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     \n"
     ]
    }
   ],
   "source": [
    "num_qubits = 5\n",
    "num_nodes = 2**num_qubits\n",
    "a = -1.0\n",
    "b = 1.0\n",
    "hat_basis = HatBasis(a=a, b=b, num_nodes=num_nodes)\n",
    "\n",
    "embed = HatBasisQFE(wires=num_qubits, basis=hat_basis, sqrt=True, normalize=False)\n",
    "obs = qml.PauliZ(0)\n",
    "model = MeasurementLayer(embed, observables=obs, measurement_type=MeasurementType.Expectation)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([0.0])\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pnts = 500\n",
    "xvals = torch.linspace(-1.0, 1.0, num_pnts).unsqueeze(-1)\n",
    "yvals = model(xvals)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(xvals, yvals)\n",
    "plt.xlabel('$x$')\n",
    "plt.title(\"$\\langle Z_0\\\\rangle$\")\n",
    "plt.savefig('./figures/z0.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = qml.PauliZ(num_qubits-1)\n",
    "model = MeasurementLayer(embed, observables=obs, measurement_type=MeasurementType.Expectation)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([0.0])\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvals = model(xvals)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(xvals, yvals)\n",
    "plt.xlabel('$x$')\n",
    "plt.title(\"$\\langle Z_4\\\\rangle$\")\n",
    "plt.savefig('./figures/zn.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = qml.PauliX(4)\n",
    "model = MeasurementLayer(embed, observables=obs, measurement_type=MeasurementType.Expectation)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([0.0])\n",
    "print(drawer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvals = model(xvals)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(xvals, yvals)\n",
    "plt.xlabel('$x$')\n",
    "plt.title(\"$\\langle X_4\\\\rangle$\")\n",
    "plt.savefig('./figures/xn.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(\n",
    "    X, threshold1=-1.0, threshold2=0.0, low_value=0.0, mid_value=2, high_value=-1.0\n",
    "):\n",
    "    condition1 = X < threshold1\n",
    "    condition2 = (X >= threshold1) & (X < threshold2)\n",
    "    condition3 = X >= threshold2\n",
    "\n",
    "    values = torch.zeros_like(X)\n",
    "    values[condition1] = low_value\n",
    "    values[condition2] = mid_value\n",
    "    values[condition3] = high_value\n",
    "\n",
    "    return values\n",
    "\n",
    "def add_gaussian_noise(tensor, mean=0.0, std=0.01):\n",
    "    return tensor + torch.randn(tensor.size()) * std + mean\n",
    "\n",
    "X = torch.linspace(-1, 1, 1000).reshape(-1, 1)\n",
    "func = step_function\n",
    "sigma = 0.1\n",
    "Y = add_gaussian_noise(func(X), std=sigma)\n",
    "plt.plot(X, Y)\n",
    "plt.savefig('./figures/stepfunc.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [qml.Identity(0), qml.PauliZ(0)]\n",
    "model = HamiltonianLayer(embed, observables=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([0.0])\n",
    "print(drawer(x))\n",
    "nump = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", nump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 50\n",
    "N_valid = 10\n",
    "batch_size = 10\n",
    "X_train = torch.linspace(-1, 1, N_train, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_train = add_gaussian_noise(func(X_train), std=sigma)\n",
    "X_valid = torch.linspace(-1, 1, N_valid, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_valid = func(X_valid)\n",
    "data_train = TensorDataset(X_train, Y_train)\n",
    "data_valid = TensorDataset(X_valid, Y_valid)\n",
    "loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "loader_valid = DataLoader(data_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "lr = 0.1\n",
    "optimizer = Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "metric = MeanAbsolutePercentageError()\n",
    "\n",
    "logger = logging.getLogger(\"train_function\")\n",
    "logger.setLevel(level=logging.INFO)\n",
    "num_epochs = 100\n",
    "trainer = SupervisedTrainer(\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\"MARE\": metric},\n",
    "    num_epochs=num_epochs,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, train_data=loader_train, valid_data=loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(-1, 1, 300, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_exact = func(X)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_model = model(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_exact, label=\"exact\", color=\"blue\")\n",
    "plt.plot(X, Y_model, label=\"predicted\", color=\"red\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend()\n",
    "plt.savefig('./figures/stepfunc_train_pptnqfe.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1\n",
    "base = 3.0\n",
    "omega = 1.0\n",
    "embed = ParallelIQPEncoding(wires=num_qubits,\n",
    "                            num_features=num_features,\n",
    "                            n_repeat=1,\n",
    "                            base=base,\n",
    "                            omega=omega)\n",
    "n_layers = 3\n",
    "var = AltRotCXLayer(wires=num_qubits, n_layers=n_layers)\n",
    "\n",
    "obs = [qml.Identity(0), qml.PauliZ(0)]\n",
    "model = HamiltonianLayer(embed, var, observables=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([1.0])\n",
    "print(drawer(x))\n",
    "nump = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", nump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "trainer = SupervisedTrainer(\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\"MARE\": metric},\n",
    "    num_epochs=num_epochs,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, train_data=loader_train, valid_data=loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(-1, 1, 300, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_exact = func(X)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_model = model(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_exact, label=\"exact\", color=\"blue\")\n",
    "plt.plot(X, Y_model, label=\"predicted\", color=\"red\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend()\n",
    "plt.savefig('./figures/stepfunc_train_iqpe.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigonometric(X, a=1, b=math.pi, c=0.):\n",
    "    return a * torch.sin(b * X + c)\n",
    "\n",
    "X = torch.linspace(-1, 1, 1000).reshape(-1, 1)\n",
    "func = trigonometric\n",
    "sigma = 0.1\n",
    "Y = add_gaussian_noise(func(X), std=sigma)\n",
    "plt.plot(X, Y)\n",
    "plt.savefig('./figures/sin.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M2)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(1.36,5.74,5.80)â”€â”€â”€\n",
      "1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M1)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°U(M2)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(1.14,4.92,2.64)â”€â”€â”€\n",
      "2: â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M1)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°U(M1)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(3.20,4.89,0.33)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "3: â”€â•­U(M0)â”€â•°U(M1)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(3.94,5.34,3.90)â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(3.33,1.74,4.82)â”€â•­â—\n",
      "4: â”€â•°U(M0)â”€â”€Rot(5.16,1.06,1.27)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(5.56,4.58,1.01)â”€â•°X\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€Rot(1.65,5.91,2.03)â”€â•­â—â”€â”€Rot(0.29,3.72,2.42)â”€â•­â—\n",
      "â”€â”€â”€Rot(0.32,3.15,1.61)â”€â•­â—â”€â”€Rot(0.54,3.91,0.48)â”€â•°Xâ”€â”€Rot(0.60,0.95,4.78)â”€â•°Xâ”€â”€Rot(1.97,0.02,2.60)â”€â•°X\n",
      "â”€â”€â”€Rot(4.37,3.11,5.60)â”€â•°Xâ”€â”€Rot(2.57,3.67,2.41)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€Rot(2.34,4.93,1.24)â”€â•­â—â”€â”€Rot(0.31,3.44,6.06)â”€â•­â—â”€â”€Rot(1.83,1.10,3.36)â”€â•°X\n",
      "â”€â”€â”€Rot(2.58,1.76,4.34)â”€â•°Xâ”€â”€Rot(6.15,3.00,3.04)â”€â•°Xâ”€â”€Rot(5.66,0.54,2.13)â”€â•°Xâ”€â”€Rot(2.35,1.28,2.97)â”€â”€â”€\n",
      "â”€â”€â”€Rot(3.98,3.61,4.24)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€Rot(3.39,4.87,0.74)â”€â•­â—â”€â”€Rot(5.67,4.19,4.93)â”€â•­â—â”€â”€Rot(1.11,4.27,1.87)â”€â”¤ â•­<ğ“—>\n",
      "â”€â”€â”€Rot(1.74,3.76,3.70)â”€â•°Xâ”€â”€Rot(5.27,3.54,5.51)â”€â•°Xâ”€â”€Rot(4.35,2.85,2.29)â”€â”¤ â”œ<ğ“—>\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œ<ğ“—>\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œ<ğ“—>\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â•°<ğ“—>\n",
      "Number of parameters:  93\n"
     ]
    }
   ],
   "source": [
    "embed = HatBasisQFE(wires=num_qubits, basis=hat_basis, sqrt=True, normalize=False)\n",
    "num_mps_layers = 1\n",
    "num_block_layers = 3\n",
    "reverse = True\n",
    "var = TwoQubitRotCXMPSLayer(num_qubits, \n",
    "                            n_layers_mps=num_mps_layers,\n",
    "                            n_layers_block=num_block_layers,\n",
    "                            reverse=reverse)\n",
    "\n",
    "obs = [qml.Identity(0)] + [qml.PauliZ(j) for j in range(num_qubits)]\n",
    "model = HamiltonianLayer(embed, var, observables=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([0.0])\n",
    "print(drawer(x))\n",
    "nump = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", nump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 50\n",
    "N_valid = 10\n",
    "batch_size = 10\n",
    "X_train = torch.linspace(-1, 1, N_train, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_train = add_gaussian_noise(func(X_train), std=sigma)\n",
    "X_valid = torch.linspace(-1, 1, N_valid, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_valid = func(X_valid)\n",
    "data_train = TensorDataset(X_train, Y_train)\n",
    "data_valid = TensorDataset(X_valid, Y_valid)\n",
    "loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "loader_valid = DataLoader(data_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "num_epochs = 100\n",
    "trainer = SupervisedTrainer(\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\"MARE\": metric},\n",
    "    num_epochs=num_epochs,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, train_data=loader_train, valid_data=loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(-1, 1, 300, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_exact = func(X)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_model = model(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_exact, label=\"exact\", color=\"blue\")\n",
    "plt.plot(X, Y_model, label=\"predicted\", color=\"red\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend()\n",
    "plt.savefig('./figures/sin_train_pptnqfe.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1\n",
    "base = 3.0\n",
    "omega = 1.0\n",
    "embed = ParallelIQPEncoding(wires=num_qubits,\n",
    "                            num_features=num_features,\n",
    "                            n_repeat=1,\n",
    "                            base=base,\n",
    "                            omega=omega)\n",
    "n_layers = 3\n",
    "var = AltRotCXLayer(wires=num_qubits, n_layers=n_layers)\n",
    "\n",
    "obs = [qml.Identity(0)] + [qml.PauliZ(j) for j in range(num_qubits)]\n",
    "model = HamiltonianLayer(embed, var, observables=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([1.0])\n",
    "print(drawer(x))\n",
    "nump = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", nump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "trainer = SupervisedTrainer(\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\"MARE\": metric},\n",
    "    num_epochs=num_epochs,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, train_data=loader_train, valid_data=loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(-1, 1, 300, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_exact = func(X)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_model = model(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_exact, label=\"exact\", color=\"blue\")\n",
    "plt.plot(X, Y_model, label=\"predicted\", color=\"red\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend()\n",
    "plt.savefig('./figures/sin_train_iqpe.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 1\n",
    "var = AltRotCXLayer(wires=num_qubits, n_layers=n_layers)\n",
    "\n",
    "obs = [qml.Identity(0)] + [qml.PauliZ(j) for j in range(num_qubits)]\n",
    "model = HamiltonianLayer(embed, var, observables=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([1.0])\n",
    "print(drawer(x))\n",
    "nump = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", nump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "trainer = SupervisedTrainer(\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\"MARE\": metric},\n",
    "    num_epochs=num_epochs,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, train_data=loader_train, valid_data=loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(-1, 1, 300, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_exact = func(X)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_model = model(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_exact, label=\"exact\", color=\"blue\")\n",
    "plt.plot(X, Y_model, label=\"predicted\", color=\"red\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend()\n",
    "plt.savefig('./figures/sin_train_iqpe_l0.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost value: 1.0557280902123383\n",
      "[-1.00000425 -1.00000176 -1.00000105 -1.00000063 -1.00000044 -1.00000013\n",
      " -0.99999987 -0.99999966 -0.99999941 -0.99999901 -0.9999989  -0.99999868\n",
      " -0.99999836 -0.99999774 -0.61803559 -0.61803239  0.99999774  0.99999836\n",
      "  0.99999868  0.9999989   0.99999901  0.99999941  0.99999966  0.99999987\n",
      "  1.00000013  1.00000044  1.00000063  1.00000105  1.00000176  1.00000425\n",
      "  1.61803294  1.61803504]\n"
     ]
    }
   ],
   "source": [
    "num_qubits = 5\n",
    "def construct_matrix(c):\n",
    "    size = 2**num_qubits\n",
    "    H = np.zeros((size, size), dtype=complex)\n",
    "    np.fill_diagonal(H[:2], 1)\n",
    "    np.fill_diagonal(H[-2:], -1)\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(size):\n",
    "        for j in range(i+1, size):\n",
    "            H[i, j] = complex(0, c[counter])\n",
    "            counter += 1\n",
    "\n",
    "    H = H + H.conj().T - np.diag(H.diagonal())\n",
    "    return H\n",
    "\n",
    "def objective_function(c):\n",
    "    H = construct_matrix(c)\n",
    "    size = H.shape[0]\n",
    "    half = int(size/2)\n",
    "    eigenvalues = np.linalg.eigvalsh(H)\n",
    "    eigenvalues_sorted = np.sort(eigenvalues)[::-1]\n",
    "    target_eigenvalues = [1]*half+[-1]*half\n",
    "    \n",
    "    error = np.sum((eigenvalues_sorted - target_eigenvalues)**2)\n",
    "    return error\n",
    "\n",
    "num_params = (2**num_qubits * (2**num_qubits - 1)) // 2\n",
    "initial_guesses = np.ones(num_params)\n",
    "result = sp.optimize.minimize(objective_function, initial_guesses, method='BFGS')\n",
    "\n",
    "optimized_c = result.x\n",
    "print(\"Cost value:\", result.fun)\n",
    "\n",
    "H = construct_matrix(optimized_c)\n",
    "eigs, U = np.linalg.eigh(H)\n",
    "print(eigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5533e-14], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M2)â”€â•­U(M3)â”€â”¤  <ğ“—(0.65)>\n",
      "1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M1)â”€â•°U(M2)â”€â”œU(M3)â”€â”¤           \n",
      "2: â”€â”€â”€â”€â”€â”€â”€â”€â•­U(M1)â”€â•°U(M1)â”€â”€â”€â”€â”€â”€â”€â”€â”œU(M3)â”€â”¤           \n",
      "3: â”€â•­U(M0)â”€â•°U(M1)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”œU(M3)â”€â”¤           \n",
      "4: â”€â•°U(M0)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°U(M3)â”€â”¤           \n",
      "Number of parameters:  1\n"
     ]
    }
   ],
   "source": [
    "a = -1.0\n",
    "b = 1.0\n",
    "num_nodes = 2**num_qubits\n",
    "hat_basis = HatBasis(a=a, b=b, num_nodes=num_nodes)      \n",
    "embed = HatBasisQFE(wires=num_qubits, basis=hat_basis, sqrt=True, normalize=False)\n",
    "var = embedU(num_qubits, U.conj().T)\n",
    "\n",
    "obs = [qml.PauliZ(0)]\n",
    "model = HamiltonianLayer(embed, var, observables=obs)\n",
    "drawer = qml.draw(model.qnode, show_all_wires=True, expansion_strategy=\"device\")\n",
    "x = torch.tensor([-0.1429])\n",
    "y = model(x)\n",
    "print(y)\n",
    "print(drawer(x))\n",
    "nump = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", nump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yvals = model(xvals)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(xvals, yvals)\n",
    "plt.xlabel('$x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(\n",
    "    X, threshold1=-0.9, threshold2=0.9, low_value=2.0, mid_value=0, high_value=-2.0\n",
    "):\n",
    "    condition1 = X < threshold1\n",
    "    condition2 = (X >= threshold1) & (X < threshold2)\n",
    "    condition3 = X >= threshold2\n",
    "\n",
    "    values = torch.zeros_like(X)\n",
    "    values[condition1] = low_value\n",
    "    values[condition2] = mid_value\n",
    "    values[condition3] = high_value\n",
    "\n",
    "    return values\n",
    "\n",
    "X = torch.linspace(-1, 1, 1000).reshape(-1, 1)\n",
    "func = step_function\n",
    "sigma = 0.1\n",
    "Y = add_gaussian_noise(func(X), std=sigma)\n",
    "plt.plot(X, Y)\n",
    "plt.savefig('./figures/segments.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 50\n",
    "N_valid = 10\n",
    "batch_size = 10\n",
    "X_train = torch.linspace(-1, 1, N_train, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_train = add_gaussian_noise(func(X_train), std=sigma)\n",
    "X_valid = torch.linspace(-1, 1, N_valid, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_valid = func(X_valid)\n",
    "data_train = TensorDataset(X_train, Y_train)\n",
    "data_valid = TensorDataset(X_valid, Y_valid)\n",
    "loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "loader_valid = DataLoader(data_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "lr = 0.1\n",
    "optimizer = Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "\n",
    "num_epochs = 100\n",
    "trainer = SupervisedTrainer(\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\"MARE\": metric},\n",
    "    num_epochs=num_epochs,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, train_data=loader_train, valid_data=loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.linspace(-1, 1, 300, dtype=torch.float64).reshape(-1, 1)\n",
    "Y_exact = func(X)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_model = model(X)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_exact, label=\"exact\", color=\"blue\")\n",
    "plt.plot(X, Y_model, label=\"predicted\", color=\"red\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend()\n",
    "plt.savefig('./figures/twosteps_train_pptnqfe.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
